{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Consider text paragraph.So, keep working. Keep striving. Never give up. Fall down seven times, get\n",
        "up eight. Ease is a greater threat to progress than hardship. Ease is a greater threat to progress than\n",
        "hardship. So, keep moving, keep growing, keep learning. See you at work.Preprocess the text to remove\n",
        "any special characters and digits. Generate the summary using extractive summarization process."
      ],
      "metadata": {
        "id": "b3UBF-kQj-YJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WciYW2UV2Dg_",
        "outputId": "d3634228-961e-4438-a596-9e3994f89378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMCL3djr2Jle",
        "outputId": "b31f60fe-0cc5-4a72-c20f-cefe6eb60b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbqOA3t_2Xk2",
        "outputId": "3a959447-878a-4adf-c4af-e13027e91e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q400rL-Yj9n6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "8fa8d5e7-4a26-440b-c9e7-6a6cafe60c82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ease is a greater threat to progress than hardship.Ease is a greater threat to progress than \\nhardship.So, keep moving, keep growing, keep learning. o, keep working.Keep striving.Fall down seven times, get \\nup eight.Never give up.See you at work'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "import re\n",
        "\n",
        "def get_process_text(text):\n",
        "    process_text= re.sub(r'[^a-zA-Z\\s]' , '' , text)\n",
        "    process_text = re.sub(r'\\d+','',process_text)\n",
        "    return process_text\n",
        "\n",
        "text = \"\"\" o, keep working. Keep striving. Never give up. Fall down seven times, get\n",
        "up eight. Ease is a greater threat to progress than hardship. Ease is a greater threat to progress than\n",
        "hardship. So, keep moving, keep growing, keep learning. See you at work\"\"\"\n",
        "\n",
        "process_text = get_process_text(text)\n",
        "\n",
        "# get all the stop words\n",
        "stopWords = set(stopwords.words(\"english\"))\n",
        "words = word_tokenize(process_text)\n",
        "\n",
        "# count the frequency of each word\n",
        "word_freq ={}\n",
        "for word in words:\n",
        "    if word in stopWords:\n",
        "        continue\n",
        "    if word in word_freq:\n",
        "        word_freq[word]+=1\n",
        "    else:\n",
        "        word_freq[word] = 1\n",
        "\n",
        "maximum_frq  = max(word_freq.values())\n",
        "\n",
        "for word in word_freq.keys():\n",
        "    word_freq[word] = (word_freq[word]/maximum_frq)\n",
        "\n",
        "# tokenize the sentence\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "sentence_values = {}\n",
        "for sentence in sentences:\n",
        "    for word,frq in word_freq.items():\n",
        "        if word in sentence.lower():\n",
        "            if sentence in sentence_values:\n",
        "                sentence_values[sentence]+= frq\n",
        "            else:\n",
        "                sentence_values[sentence] = frq\n",
        "\n",
        "import heapq\n",
        "\n",
        "summary = heapq.nlargest(10 , sentence_values , key = sentence_values.get)\n",
        "summary = ''.join(summary)\n",
        "summary"
      ]
    }
  ]
}